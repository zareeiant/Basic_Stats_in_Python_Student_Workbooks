{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import thinkplot\n",
    "import thinkstats2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.stats as ss\n",
    "import math\n",
    "import random\n",
    "\n",
    "##Seaborn for fancy plots. \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams[\"figure.figsize\"] = (12,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation Applications\n",
    "\n",
    "We can use our estimation skillz to do some more stuff beyond estimating the population. \n",
    "\n",
    "### But First, Estimate a Population\n",
    "\n",
    "We can keep estimating populations with our analytical distribution. First - we'll do another normal one, but we'll grab some extra data to investigate it a bit more along the way. \n",
    "\n",
    "Our simulator will be like last time, it'll take in the emperical statistics from our sample, run a bunch of trials for generating analytical sample datasets, total those results up for analysis, and return it back. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulate Normal - from last time\n",
    "#\n",
    "#Add a return to send back the means and the predictions. \n",
    "#\n",
    "def simulateNormal(mu=0, sigma=1, n=100, m=10000, ciLow=5, ciHi=95):\n",
    "    means = [] #List of all the means that are created. \n",
    "    preds = []\n",
    "    for j in range(m): #Run m number of simulations. \n",
    "        xs = np.random.normal(mu, sigma, n) #Generate a normal dist based on emperical data. \n",
    "        xbar = np.mean(xs) #Take the mean of the dist above's values\n",
    "        means.append(xbar) #Add to list. \n",
    "        preds.append(xs)\n",
    "    cdf = thinkstats2.Cdf(means) #Make a CDF of the means of the analytical dist's\n",
    "    ci = cdf.Percentile(ciLow), cdf.Percentile(ciHi) #5th, 95th percentiles. \n",
    "    muList = [mu] * m\n",
    "    stderr = mean_squared_error(means, muList, squared=False) #RMSE of how different the random analytical means are from the emp. mean. \n",
    "    return cdf, ci, stderr, means, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll add these error calculators, we'll use them later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MeanError(estimates, actual):\n",
    "    errors = [estimate-actual for estimate in estimates]\n",
    "    return np.mean(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(estimates, actual):\n",
    "    e2 = [(estimate-actual)**2 for estimate in estimates]\n",
    "    mse = np.mean(e2)\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Some Data - Using LogNormal Data\n",
    "\n",
    "Here we'll use some real data, data that has already been transformed to help us. The log.annual.inc value is the income <b><i>after</i></b> it has been transformed. This takes it from its original lognormal format to a normal distribution, which we know how to analyze easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load some data\n",
    "df = pd.read_csv(\"data/loan_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Warmup - Estimate Normal Distribution for Income</h3>\n",
    "\n",
    "We are given the log.annual.inc, which is the income of the applicants, run through a log transformation. Take a look via a graph...\n",
    "\n",
    "We can also plot the de-logged, or exponential transformed, income, which should be our orignal incomes. We should double check to see if it makes sense, and to see what it looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph distribution of log income\n",
    "thinkplot.PrePlot(2, 2, 1)\n",
    "sns.histplot(df[\"log.annual.inc\"], kde=True)\n",
    "thinkplot.SubPlot(2)\n",
    "sns.histplot(np.exp(df[\"log.annual.inc\"]), kde=True).set(xlim=(0,200000))\n",
    "plt.axvline(np.mean(np.exp(df[\"log.annual.inc\"])), color=\"red\")\n",
    "plt.axvline(np.median(np.exp(df[\"log.annual.inc\"])), color=\"green\")\n",
    "plt.ticklabel_format(style='plain', axis='x')\n",
    "thinkplot.Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>When lognormal is normal!</h3>\n",
    "\n",
    "The log.annual.inc value looks really normal - estimate the income of the population as a whole. \n",
    "\n",
    "<b>Note:</b> this data is the income data, that has been transformed, with a log transformation. This is one example of some ways that we can use a transformation to make analysis easier. Transform the data into somehting that is easy to analyze, like a normal dist, do what you need to do, then transform in reverse to get raw data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original distribution above could be analyzed directly via modelling it with a lognorm distribution, like we'll try below, but normal things are generally more simple, that's why this data was pretransformed. This is easier for lognorm stuff.  \n",
    "\n",
    "#### Keep Working, Looking Backwards\n",
    "\n",
    "Work with the data (already logged, the original format). First we'll do a little demonstration - the simulateNormal function also returns the \"preds\" value, which is the actual raw set of the predictions. This is the core of the estimations that we were doing before - we generate a bunch of \"fake\" distributions - each showing what we <b>expect</b> the distribution of the data to be like if it is actually following a normal distribution with the statistics (mean, standard deviation, and count) found in the emperical data. This plot draws each of those anticipated distributions at once, we can see that each one differs a little bit, but as more and more are drawn we can conclude a clear pattern. \n",
    "\n",
    "For the estimation before, we were taking the means of each of these distributions, and each of those is one prediction of the population mean. Our best estimate was the mean of those means. \n",
    "\n",
    "<b>Note:</b> play with the n and m values a little to draw different nubmers - the n value, or the sample size of the emperical data, will drastically impact the spread of the different sets of predictions. This should make sense - if we sample 10 people, their incomes may be distributed very randomly; if we sample 10,000 people, the true distribution of the data will outweigh those random low probability events. E.g. if you sample 10 Edmonton are residents for income, you might get 2 Oilers who make millions, which would make your income distribution look nothing like reality; this is unlikely, but definately possible. If you sample 10,000 people, maybe you still get 2 Oilers (the oilers are ~25 people out of ~1.3 million, so the odds of getting multiple of them is still extremely unlikely) but those 2 values will minorly impact 10,000 values while they will overwhelm 10 values. This is basically how sample size increases help with accuracy - though the differences are subtle, not massive differences with outliers, which may likely be filtered out anyway. \n",
    "\n",
    "##### Alternate Outliering - the Median\n",
    "\n",
    "If we do encounter something like outliers messing up our data, one thing to potentially try is to take the power of the median and the normal distribution into our hands. We'll use two facts:\n",
    "<ul>\n",
    "<li> The median is less impacted by outliers. \n",
    "<li> In a true normal distribution, the mean and median will be equal. \n",
    "</ul>\n",
    "\n",
    "What's the end result - we can try replacing the mean with the median if outliers make an outsized concern. This is a bit of a hack, yes, but we are changing our approach to target our goal. We wish to estimate the mean income of the population as a whole - if we run into a scenario that using the emperical mean causes our analytical distributions to mirror the real distribution worse, we can make a judgement call to sawap it. Things such as this are not uncommon, we don't want to generate 100% accurate stats from the emperical data, though that may be nice, we want to use that emperical data as a tool to estimate - if we need to alter it, we can. We are basically making an assertion that the median will be a better estimator than the mean - or it will introduce less error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate estimators for normal data. \n",
    "mu = df[\"log.annual.inc\"].mean()\n",
    "sig = df[\"log.annual.inc\"].std()\n",
    "n = df[\"log.annual.inc\"].count()\n",
    "med = df[\"log.annual.inc\"].median()\n",
    "print(\"Mean:\",mu,\" Median:\",med)\n",
    "\n",
    "#Run Estimations. \n",
    "cdf, ci, stderr, means, preds = simulateNormal(mu=med, sigma=sig, n=20, m=20, ciLow=5, ciHi=95)\n",
    "\n",
    "#Graph each of those predictions from above - 1000 originally. \n",
    "for i in range(len(preds)):\n",
    "    sns.kdeplot(preds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the log removed\n",
    "for i in range(len(preds)):\n",
    "    sns.kdeplot(np.exp(preds[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What's This?\n",
    "\n",
    "Each of those trial runs of the analytical distribution is slightly different, as we can see here. Each individual prediction varries, depending largely on:\n",
    "<ul>\n",
    "<li> The emperical sample size. \n",
    "<li> The closeness of the emperical/analytical distribution match. \n",
    "<li> The varriance in the data. \n",
    "</ul>\n",
    "\n",
    "The better we get on those metrics, the less error there is in our projections, and the more accurately we can expect to estimate or predict. \n",
    "\n",
    "#### CDF of the Means\n",
    "\n",
    "We are 90% confident that we are between the two CI limits. As a reminder, this CDF is made of the means of each of the distributions above - each line translates into one value, it's mean in the CDF data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thinkplot.Cdf(cdf)\n",
    "thinkplot.axvline(ci[0], color=\"red\")\n",
    "thinkplot.axvline(ci[1], color=\"red\")\n",
    "ci[0], ci[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall\n",
    "\n",
    "Each random band up there is one prediction of the distribution of the population of income. I.E. each one is one execution of the \"random\" command that generates N variables according to the distribution. \n",
    "\n",
    "The means is taking the average of all of those above predicted distributions, then averaging them together. So that is estimating the mean of the population of income M times, graphed below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the means of the above distributions\n",
    "#sns.kdeplot(means, linestyle=\"dotted\")\n",
    "thinkplot.PrePlot(2,1,2)\n",
    "sns.histplot(means)\n",
    "thinkplot.SubPlot(2)\n",
    "sns.histplot(np.exp(means))\n",
    "thinkplot.Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Show Real Data\n",
    "\n",
    "We currently have a log transformed set of data. What if we want to see the real values along with our estimate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize as original data. Limit graph to $250k to make it look OK\n",
    "df[\"income\"] = np.exp(df[\"log.annual.inc\"])\n",
    "sns.histplot(df[\"income\"], kde=True)\n",
    "plt.xlim(0,250000)\n",
    "\n",
    "convMed = np.exp(np.mean(means))\n",
    "thinkplot.axvline(convMed, color=\"red\")\n",
    "print(\"Estimated Population Mean:\", convMed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discreet Distributions\n",
    "\n",
    "Until now, we've mainly dealt with distributions like the normal, lognormal, and exponential - distributions that are continuous, or they may take on any value. We also have distributions that measure discreet things - things which may only take on specific values. Two examples below are goals in sports (hockey, soccer, etc...) or votes in an election - each of these things are counted via whole numbers. \n",
    "\n",
    "As we mentioned before, no matter the disribution we create, the process is pretty much the same. (I found this image online, and I think it is a good illustration. This is over-the-top detailed for us, it shows two standard deviations for normal on each side of the curve, but it does a reasonable job of illustrating what we need.)\n",
    "\n",
    "![Distributions](images/distributions.png \"Distributions\")\n",
    "\n",
    "The mechanics of using these discreet distributions doesn't differ all that much from the continous ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discreet Distributions in Practice\n",
    "\n",
    "#### Goals in a Game - Poisson\n",
    "\n",
    "We can approximate the expected number of goals in a game by using a Poisson distribution. It is use to model things that happen periodically, but semi-randomly - like customrers walking into a store, phone calls to a call center, or goals in some game. \n",
    "\n",
    "![Poisson](images/poisson.png \"Poisson\")\n",
    "\n",
    "<br>\n",
    "Below are a couple of examples - the input is the rate - in this case goals per game. It could be \"calls per hour\" or similar...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print a few\n",
    "ss.poisson(5).rvs(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example poisson distributions\n",
    "dist = ss.poisson(3)\n",
    "dist2 = ss.poisson(7)\n",
    "\n",
    "sns.histplot(dist.rvs(1000), binwidth=1, stat=\"density\", color=\"red\")\n",
    "sns.histplot(dist2.rvs(1000), binwidth=1, stat=\"density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Application - Forecast Games</h2>\n",
    "\n",
    "We can apply this to do a simple estimation of the Battle of Alberta. \n",
    "\n",
    "<h3>Load some data</h3>\n",
    "\n",
    "We can load some data on hockey! This came from hockey reference - it includes the goals per game for each time. Most goals wins, so we'll use that to create a model. \n",
    "\n",
    "<b>Note:</b> We are using a function to open Excel here, not a csv. Pandas probably has something to load whatever type of file you have, it just may require a different function or a different set of paramaters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and preview data\n",
    "hock = pd.read_excel(\"data/sportsref_download.xlsx\", sheet_name=\"Worksheet\", engine=\"openpyxl\", header=1)\n",
    "hock.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename column for teams\n",
    "hock = hock.rename(columns={'Unnamed: 1':\"Team\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the GOALS PER GAME column - It will be very close to GF/G, but we need to be sure!!\n",
    "hock.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Goals per game for the teams playing.\n",
    "Oil = hock[hock[\"Team\"]==\"Edmonton Oilers\"]\n",
    "gfOil = Oil[\"GF/G\"]\n",
    "print(\"Oilers Goals per Game:\", gfOil)\n",
    "Fla = hock[hock[\"Team\"]==\"Calgary Flames\"]\n",
    "gfFla = Fla[\"GF/G\"]\n",
    "print(\"Falmes Goals per Game:\", gfFla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simulate one Game\n",
    "\n",
    "Simulate one game - take the goals per game, and generate one prediction of an outcome in terms of goals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimGame(lam):\n",
    "    dist = ss.poisson(lam)\n",
    "    score = dist.rvs(1)\n",
    "    return score[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simulate Many Games\n",
    "\n",
    "Simulate a bunch of games, and check for bias in our estimator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateGame(lam=2., m=1000):\n",
    "    estimates = []\n",
    "    for i in range(m):\n",
    "        L = SimGame(lam)\n",
    "        estimates.append(L)\n",
    "\n",
    "    print('Goal Distribution:')\n",
    "    print('rmse Goals:', RMSE(estimates, lam))\n",
    "    print('mean error Goals:', MeanError(estimates, lam))\n",
    "    \n",
    "    pmf = thinkstats2.Pmf(estimates)\n",
    "    thinkplot.Hist(pmf)\n",
    "    thinkplot.Config(xlabel='Goals scored', ylabel='PMF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimateGame(gfOil, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Winners\n",
    "\n",
    "We can predict how many goals each team is to score in the simulated games, then see who scored the most. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate a bunch of games, count how many one team wins vs the other. \n",
    "def estimateMatch(team1=1, team2=1, m=1000):\n",
    "    team1Wins = []\n",
    "    ties = []\n",
    "    for i in range(m):\n",
    "        goal1 = SimGame(team1)\n",
    "        goal2 = SimGame(team2)\n",
    "        team1Wins.append(int(goal1>goal2))\n",
    "        ties.append(int(goal1 == goal2))\n",
    "    return team1Wins, ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "oil_win, oil_ties = estimateMatch(gfOil,gfFla,1000)\n",
    "np.mean(oil_win), np.mean(oil_ties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Try Some Other Teams!\n",
    "\n",
    "<b>Note:</b> this model is a simplification of the real world, probably too much of one in this case. We can try a more realistic scenario by grabbing some odds from the upcomming week's NFL gambling lines, between the Baltimore Ravens and the Tampa Bay Bradys. \n",
    "\n",
    "![lines](images/lines.png \"Lines\")\n",
    "\n",
    "This means that the bookmakers have estimated two things:\n",
    "<ul>\n",
    "<li> Baltimore is expected to score 1.5 more points than the chump deflator Tom Brady. \n",
    "<li> The total number of points scored between the two teams is expected to be 45 points. \n",
    "</ul>\n",
    "\n",
    "<b>What is the probability that Baltimore wins and destroys Brady's dreams like his marriage? </b>\n",
    "\n",
    "![Brady](images/brady.png \"Brady\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate Expected Points \n",
    "\n",
    "We can transform, with a bit of algebra, the projected total and the spread (the +/-) part into an expectation for the number of points each team will score in this game. This expectation takes the place of the previous expectation - the average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get points per game for the teams playing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Winners\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How Could this Model be Better\n",
    "\n",
    "Our point calculations are naive - we only based them on the raw expected total. For real odds, the bookmakers don't just consider a simple calculation of \"how many points\", they factor in different scenarios, matchups, injuries, weather, etc... to project who should win. In short, their internal models that are used to generate this are larger - involving more inputs, in an attempt to more thoroughly capture what impacts the outcome of a game. As well, these lines are not set to predict the exact outcome, they're set to balance betting. The bookies make money from the \"vig\" or basically a commission that is built into each bet; the -110 odds on each side of the \"spread\" bets show this - winning each pays back approximately 91% of the money, they pocket the rest. The actual lines also intend to balance the amount of money spent on each side of each bet, so they can max that vig without risking paying out massive losses. For many/most bets the true line is good, but sometimes popular teams have excessive betting, so games with the Lakers, Coyboys, and Yankees actually tend to get worse odds since their massive legion of fans will bet on them no matter what, and the bookie is incentivising bets on the other side to balance the interest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polling - Celebrate the Downfall of Democracy! \n",
    "\n",
    "Suppose we are trying to estimate who would win the previous presidental election in the US - in Arizona. \n",
    "\n",
    "<b>Note:</b> Estimating the overall win would require projecting each state individually (and dealing with Nebraska and Maine), then projecting the total electoral college votes, since in a presidential election they are effectively separate elections. Same deal, more complex model. Canada is also more complex, since you'd need to project each house seat individually in 4ish way race, then project the distribution of seats, etc... same idea, way more complex scenario. In each of these scenarios winning the most votes doesn't translate into the overall win - winning the most votes, the most times, in multiple smaller elections translates into an overall win. \n",
    "\n",
    "In real applications there's also an expectation of correlation between different elections - e.g. it is unlikely for the NDP to win all provincial ridings in west Edmonton, and lose all those in east Edmonton - there is some expected correlation that factors into overall predictions. Voter turnout also is factored in - lower turnouts tend to correspond to more conservative winners - hence the voter supression. There's also the expected sample bias, I'm an old millenial without a land line, and I don't know of any of my social circle who has ever been part of a political poll; the polling organizations know they aren't getting a perfectly representative samples so they build in corrections to their projections to correct for that. Actual polling organizations have factors like these, and others, built into their actual predictions, and this is an example of where their knowledge and skills differentiate their predictions. \n",
    "\n",
    "Having no idea how polls work has been one illustration of stats impacting the real world recently. Polls can of course \"be wrong\" and certain polling organizations generate biased projections, but much more often they are predicting things with a large amount of uncertainty and the less likely thing just happens. Even a poll that says something has an ~97% likelihood of happening is saying that the opposite will happen about one out of every 36 times - unlikely yes, but hardly a total shock - equivalent to rolling snake eyes (two dice, both ones) in a game of craps, which does happen, all the time, just ask Vegas. Legitimate polling organizations publish their confidence intervals and some sampling data at a minimum, and may share some of their interal modelling assumptions, though that is part of what makes them 'better' than their competitors, so they may not give it all. Check this document: [Polling Methodology](guides/polling_report.pdf) the Methodology section towards the end offers a good explaination of how they went about their work in executing the poll and processing the data. Media reports tend to be a very, very short summary of the real results - often to the point of removing needed context. \n",
    "\n",
    "<b>What we have here is applicable for one specific election, such as an MP/Congressman race or a state-wide race like governor or elctoral college in the states. Full elections require the above complexity. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First - Establish probability an individual vote goes for Biden or Trump.\n",
    "\n",
    "From 538: https://projects.fivethirtyeight.com/polls/president-general/arizona/ we can estimate basssed on all the previous polls that a person is approximately 49% likely to vote Biden, and 46% likely to vote Trump. \n",
    "\n",
    "Note: What 538 does to get these numbers involves some estimation already. They take multiple polls and attempt to combine them to make as accurate an estimate as possible. They try to correct for polling companies that historically skew Dem, or skew Rep, or tend to be more/less accurate. We could do this with one poll, it would be the same. \n",
    "\n",
    "Because we know (from experience) that only one of these two will actually win, we can try to isolate the share of votes of people who vote for one of these two - 3rd party votes are irrelevant. In reality, one of the things that pollsters will do is try to estimate the number of people who poll that they will vote 3rd party, then end up voting for Trump/Biden. This is an estimate they make based on past data, and domain knowledge. E.g. if we estimated that the share of 3rd party poll responses that voted T/B was skewed 2:1 towards Trump (e.g. libritarians voting Republican), we would add an adjustment here based on that knowledge. Maybe we'd add 1% to Biden's vote probability, and 2% to Trump's. This is something that really is an assumption though. These adjustments based on assumed human actions is what makes a really skilled pollster more accurate - they all know how to do the math. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How likely is it for someone to vote Trump and Biden?\n",
    "probT = .46/(.49+.46)\n",
    "print(\"Trump Prob:\", probT)\n",
    "\n",
    "probB = .49/(.49+.46)\n",
    "print(\"Biden Prob:\", probB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, of the votes that will matter, about 51.5% go Biden, 48.5% go Trump. How does this translate to a person making a vote. For each person, we can make a function to basically get one response. \n",
    "\n",
    "This person will return one vote. It will be either a vote for Trump or for Biden. That decision will be random, but it will be set with a likelihood that we calculated before - apx 51.5% of the total voters will vote Biden, as the number of votes we collect gets large. \n",
    "\n",
    "Note: for the example, we'll use a vote for Biden to be True/1. A vote for Trump is False/0. This is arbitrary. \n",
    "\n",
    "Below we have a function to generate a prediciton using a BINOMIAL distribution - it is either 1 or 0. (A 1 sample binomial dist is also called a Bernouli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate one vote, with a likelihood supplied as an argument. \n",
    "def oneVote(probCalc):\n",
    "    vote = np.random.binomial(n=1, p=probCalc)\n",
    "    return vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get one vote, is it Biden or not?\n",
    "#Run the cell a bunch of times to repeat. \n",
    "oneVote(probB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now we have our fake voter. One vote isn't good enough, we need to sample a bunch of people. \n",
    "\n",
    "Below, generate a list of n predicted voters. Then check the number that voted Biden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get an arbitrary number of simulated votes\n",
    "def getSample(voteProb, n=1000):\n",
    "    vote_list = []\n",
    "    for i in range(n):\n",
    "        vote_list.append(oneVote(voteProb))\n",
    "    return vote_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a bunch of votes, print the percentage that are Biden. \n",
    "#Try changing n and see what happens. \n",
    "tmp = getSample(probB, 5000)\n",
    "np.mean(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do Some Simulating\n",
    "\n",
    "That allows us to make one simulation. Congrats - that thing above is one simulated election. We should take a bunch though, and average their results together. \n",
    "\n",
    "We can also plot some examples to see what a difference the sample size makes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSamples(voteProb, n=1000, samples=100, ciLow=2.5, ciHi=97.5):\n",
    "    meanList = []\n",
    "    for i in range(samples):\n",
    "        meanList.append(np.mean(getSample(voteProb, n)))\n",
    "    muList = [voteProb] * samples\n",
    "    cdf = thinkstats2.Cdf(meanList) #Make a CDF of the means of the analytical dist's\n",
    "    ci = cdf.Percentile(ciLow), cdf.Percentile(ciHi) #5th, 95th percentiles. \n",
    "    stderr = mean_squared_error(meanList, muList, squared=False)\n",
    "    return meanList, stderr, cdf, ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getSamples(probB, 1000, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample Size Check\n",
    "\n",
    "Obviously, the more people we've surveyed, the more we should be able to trus our projections, or in other words, the larger our sample size is, the less our projection should waiver. \n",
    "\n",
    "All of these graphs have a fixed x-axis, the \"tigher\" the projections (probability of a Biden win) are, the more confident we are in that prediction. Or, the more likely \"that thing\" is to happen, and the less likely some \"far away thing\" is to happen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print a grid of differnet n values\n",
    "\n",
    "countHist = 5\n",
    "nVals = [10,100,1000,10000,100000,1000000]\n",
    "thinkplot.PrePlot(6,rows=2,cols=3)\n",
    "samples = 100\n",
    "\n",
    "for i in range(countHist):\n",
    "    tmpH, err, cdf, ci = getSamples(probB, nVals[i], samples)\n",
    "    thinkplot.SubPlot(i+1)\n",
    "    sns.kdeplot(tmpH).set(xlim=(0,1))\n",
    "    print(\"Error:\", err)\n",
    "thinkplot.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And the CDFs\n",
    "from matplotlib.pyplot import xlim\n",
    "\n",
    "\n",
    "for i in range(countHist):\n",
    "    tmpH, err, cdf, ci = getSamples(probB, nVals[i], samples)\n",
    "    thinkplot.SubPlot(i+1)\n",
    "    thinkplot.Cdf(cdf)\n",
    "    print(\"Error:\", err)\n",
    "thinkplot.Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above are multiple executions, with multiple n values. What we should see is that as we get larger and larger n values - the number of 'surveys' taken, we should get closer and closer to a normal curve centered around the expected percentage of votes for Biden = 51.5%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Winner!!!!\n",
    "\n",
    "Now we can calculate our projections!\n",
    "\n",
    "We don't really want to know what percentage of votes Biden is going to get, we want to know how likely he is to win. What we can do below is run some simulations, and for each one see if Biden wins, or if he looses, and then count them up. In each simulation, one candidate will get the most votes, and be declared the winner. \n",
    "\n",
    "The three lines below show us the scenarios at each end of the error - the worst and best case expected scenarios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run a bunch of trials and count how many Biden wins in. \n",
    "trials = 1000\n",
    "means, err, cdfFin, ciFin = getSamples(probB, n=700, samples=trials)\n",
    "lowest = means - err\n",
    "highest = means + err\n",
    "bWins = 0 \n",
    "for i in range(len(means)):\n",
    "    if means[i] > .5000:\n",
    "        bWins = bWins + 1\n",
    "print(bWins/trials)\n",
    "\n",
    "sns.kdeplot(means)\n",
    "sns.kdeplot(lowest)\n",
    "sns.kdeplot(highest)\n",
    "thinkplot.axvline(.5, color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Projection of Winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thinkplot.Cdf(cdfFin)\n",
    "thinkplot.axvline(ciFin[0], color=\"red\")\n",
    "thinkplot.axvline(ciFin[1], color=\"red\")\n",
    "print(\"Fraction of Scenarios where Biden wins is %.1f%% \" % ((1-cdfFin.Prob(.50))*100))\n",
    "print(\"We are 95 percent confident that Biden will get between %.1f%% and %.1f%% percent of the vote\" % (ciFin[0]*100, ciFin[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results\n",
    "\n",
    "So, roughly a 4/5 chance Biden wins. The alternative is much less likely, but still very possible. \n",
    "\n",
    "![Biden](images/biden.jpeg \"Biden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Election\n",
    "\n",
    "There's going to be an election for the president of your class. There are 3 candidates, and the latest pre-election polling results by the school newspaper were:\n",
    "<ul>\n",
    "<li> Tricky Nicky - 38 votes\n",
    "<li> Crazy Jimmy - 34 votes\n",
    "<li> Silly Willie - 1 vote\n",
    "</ul>\n",
    "\n",
    "You feel that the polls are plausible, based on your subjective judgement of the feelings before the election. You want to embarrass those school newspaper nerds and make a more accurate prediction. <b>What is the probability of each candidate winning the election? And what is the 90% CI of Jimmy winning?</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate vote probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>I will label Jimmy winning as 1. So this is a calculation of the probability that Jimmy wins.<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run a bunch of trials and count how many jimmy wins in. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CDF For Win Totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate final win predictions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml3950')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d722d3adfa415172c1f5238b519fb86b488acdae450fd691ab06c09f4ca9173"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
