{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \t\n",
    "import matplotlib.pyplot as plt \n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fractions import Fraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes - From Scratch\n",
    "\n",
    "We can expand on the the idea of Bayesean updates with multiple features into a full predictive model. \n",
    "\n",
    "## Parts of the Model\n",
    "\n",
    "Our predictive model needs to do a few things. The main conceptual difference between this model and doing the Bayes tables is that here we will pre-calculate all of the potential calculations of likelihood that we may need. In the tables, every time we saw a new feature we then calculated its likelihood and updated our probability with it when we did the update to generate the unnormalized and posterior probabilities. Here we will pre-calculate each of those likelihoods ahead of time in the fitting step, so when a prediction needs to be made we can just look up the matching likelihoods and do the multiplication to calculate the answer. Doing it like this means all of the heavy lifting (calculating all of the probabilities) is done while fitting, and creating predictions is fast. \n",
    "\n",
    "### Initialization\n",
    "\n",
    "The initialization step will just setup the pieces that we'll need. Here our initialization declares empty varaibles that will hold everything we calculate and figure out. \n",
    "\n",
    "### Train the Model\n",
    "\n",
    "The training process is where the model is \"built\", or where it learns all of the information it needs to be able to make predictions. This is the majority of the work. In short, we need to:\n",
    "<ul>\n",
    "<li> Create a list of all the features in our data. \n",
    "<li> Create a list of all of the likelihood possibilities. \n",
    "    <ul>\n",
    "    <li> This is a list of all the potential feature_outcome pairs that is possible. \n",
    "    <li> \n",
    "    <li> The format, with an underscore between the feature and value is arbitrary - we are only creating a replicable item to represent that combination, it could theoretically be anything. \n",
    "    </ul>\n",
    "<li> Calculate the actual likelihood probabilities. \n",
    "    <ul>\n",
    "    <li> For each of the possible likelihoods, calculate its actual likelihood value. \n",
    "    <li> I.e. what is the actual probability of playing golf given that it is sunny.\n",
    "    <li> This is the \"flipped conditional\" part of the Bayes equation. \n",
    "    </ul>\n",
    "<li> Calculate class prior probabilities. \n",
    "    <ul>\n",
    "    <li> This is the other part of the numerator in the Bayes equation. \n",
    "    </ul>\n",
    "<li> Calculate the prior probabilities for the features. \n",
    "    <ul>\n",
    "    <li> How likely is each potential value for each feature. \n",
    "    <li> Used for the bottom of the Bayes equation. \n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "Once done training, no matter what our data actually says, we should have all of the probabilities for it pre-calculated in one of our data structures. \n",
    "\n",
    "### Predict\n",
    "\n",
    "To make a prediction we just need to look up the correct probabilities, and perform the calculation. \n",
    "\n",
    "### Important Bayes Note\n",
    "\n",
    "One problem that can occur with Bayes is the \"zero count\" problem, or what if we have a valid value for one of our features that just doesn't occur in our training data. For example, what if there was a day that we were predicting with our weather and golf model where the Humidity was \"Dry\"? When we attempt to look up the probability of \"Humidity = Dry\" there won't be anything there and the probability will be 0, since we didn't train for it. Since this will popup on the bottom of the division in the equation, that'll be an issue. This problem is resolved through something called Laplace (or Additive) Smoothing. We won't implement this immediately here (maybe next week? maybe for a fun weekend exercise?) but the idea is relatively simple - when calculating the probability of something, rather than doing the normal calculation of:\n",
    "\n",
    "$ P(A) = \\frac{count-of-A}{total-elements} $\n",
    "\n",
    "We change that to:\n",
    "\n",
    "$ P(A) = \\frac{count-of-A + alpha}{total-elements + (alpha*number-of-features)} $\n",
    "\n",
    "Where alpha is a chosen constant, usually 1. We'll look at how to choose a good alpha when we look at tuning models, the short answer is guess and test. \n",
    "\n",
    "This smoothing correction seves to make sure that our model can handle new values without just failing, at the expense of a very minor impact to accuracy on predicted probabilities for things we do know. If a new unseen value comes in, rather than it's probability being 0, which will cause the overall cacluation to fail, its probability will be some small value - almost certainly unlikely to make a tangible difference in our calculations, but enough to keep things rolling. In other words we've sacrificed a tiny bit of accuracy in exchange for much more generalizability. With datasets of a reasonable size, the small additions of the smoothing calculation don't make much of a difference. \n",
    "\n",
    "In a perfect world, where we knew every possibility ahead of time and had it embedded in our training data, this smoothing would not be useful and we would not consider it. In reality, Bayes is often used for things like spam detection, where the incoming features are words from the text of an email - in such a case, it is very likely that we will encounter new things when making predictions, so this smoothing is used very frequently when using a Naive Bayes model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(table):\n",
    "    \"\"\"Compute the posterior probabilities.\"\"\"\n",
    "    table['unnorm'] = table['prior'] * table['likelihood']\n",
    "    prob_data = table['unnorm'].sum()\n",
    "    table['posterior'] = table['unnorm'] / prob_data\n",
    "    return prob_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Windy</th>\n",
       "      <th>Play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>f</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>t</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>f</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>f</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>f</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Outlook  Temp Humidity Windy Play\n",
       "0     Rainy   Hot     High     f   no\n",
       "1     Rainy   Hot     High     t   no\n",
       "2  Overcast   Hot     High     f  yes\n",
       "3     Sunny  Mild     High     f  yes\n",
       "4     Sunny  Cool   Normal     f  yes"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table(\"data/weather.txt\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updates\n",
    "\n",
    "We can do a warm-up to making our model by making an update table simplified version. \n",
    "\n",
    "What is the probability of playing when the weather is Sunny, Hot, Normal, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Play</th>\n",
       "      <td>9/14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not Play</th>\n",
       "      <td>5/14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prior\n",
       "Play      9/14\n",
       "Not Play  5/14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = pd.DataFrame(index=[\"Play\", \"Not Play\"])\n",
    "total = len(df)\n",
    "dfPlay = df[df[\"Play\"] == \"yes\"]\n",
    "dfNoPlay = df[df[\"Play\"] == \"no\"]\n",
    "pPlay = Fraction(len(df[df[\"Play\"] == \"yes\"]), total)\n",
    "weather[\"prior\"] = pPlay, (1 - pPlay)\n",
    "updates = 1\n",
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>unnorm</th>\n",
       "      <th>posterior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Play</th>\n",
       "      <td>9/14</td>\n",
       "      <td>1/3</td>\n",
       "      <td>3/14</td>\n",
       "      <td>3/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not Play</th>\n",
       "      <td>5/14</td>\n",
       "      <td>2/5</td>\n",
       "      <td>1/7</td>\n",
       "      <td>2/5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prior likelihood unnorm posterior\n",
       "Play      9/14        1/3   3/14       3/5\n",
       "Not Play  5/14        2/5    1/7       2/5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if_playOut = Fraction(len(dfPlay[dfPlay[\"Outlook\"] == \"Sunny\"]), len(dfPlay))\n",
    "if_notOut = Fraction(len(dfNoPlay[dfNoPlay[\"Outlook\"] == \"Sunny\"]), len(dfNoPlay))\n",
    "weather[\"likelihood\"] = if_playOut, if_notOut\n",
    "update(weather)\n",
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update Table\n",
    "\n",
    "We'll tweak the prevous update steps to handle multiple rounds. This isn't the most efficient way to do this, we're digging through the details here. \n",
    "\n",
    "We will run the updates just as we did before, the change here is each time I'll rename the old prior and likelihood values, so we keep everything as we go though. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior1</th>\n",
       "      <th>likelihood1</th>\n",
       "      <th>prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Play</th>\n",
       "      <td>9/14</td>\n",
       "      <td>1/3</td>\n",
       "      <td>3/14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not Play</th>\n",
       "      <td>5/14</td>\n",
       "      <td>2/5</td>\n",
       "      <td>1/7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prior1 likelihood1 prior\n",
       "Play       9/14         1/3  3/14\n",
       "Not Play   5/14         2/5   1/7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = weather.rename(columns={\"prior\": str(\"prior\"+str(updates)), \"unnorm\": \"prior\", \"likelihood\":(\"likelihood\"+str(updates))})\n",
    "weather = weather.drop(columns={\"posterior\"})\n",
    "updates += 1\n",
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior1</th>\n",
       "      <th>likelihood1</th>\n",
       "      <th>prior</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>unnorm</th>\n",
       "      <th>posterior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Play</th>\n",
       "      <td>9/14</td>\n",
       "      <td>1/3</td>\n",
       "      <td>3/14</td>\n",
       "      <td>2/9</td>\n",
       "      <td>1/21</td>\n",
       "      <td>5/11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not Play</th>\n",
       "      <td>5/14</td>\n",
       "      <td>2/5</td>\n",
       "      <td>1/7</td>\n",
       "      <td>2/5</td>\n",
       "      <td>2/35</td>\n",
       "      <td>6/11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prior1 likelihood1 prior likelihood unnorm posterior\n",
       "Play       9/14         1/3  3/14        2/9   1/21      5/11\n",
       "Not Play   5/14         2/5   1/7        2/5   2/35      6/11"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if_playTemp = Fraction(len(dfPlay[dfPlay[\"Temp\"] == \"Hot\"]), len(dfPlay))\n",
    "if_notTemp = Fraction(len(dfNoPlay[dfNoPlay[\"Temp\"] == \"Hot\"]), len(dfNoPlay))\n",
    "weather[\"likelihood\"] = if_playTemp, if_notTemp\n",
    "update(weather)\n",
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior1</th>\n",
       "      <th>likelihood1</th>\n",
       "      <th>prior2</th>\n",
       "      <th>likelihood2</th>\n",
       "      <th>prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Play</th>\n",
       "      <td>9/14</td>\n",
       "      <td>1/3</td>\n",
       "      <td>3/14</td>\n",
       "      <td>2/9</td>\n",
       "      <td>1/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not Play</th>\n",
       "      <td>5/14</td>\n",
       "      <td>2/5</td>\n",
       "      <td>1/7</td>\n",
       "      <td>2/5</td>\n",
       "      <td>2/35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prior1 likelihood1 prior2 likelihood2 prior\n",
       "Play       9/14         1/3   3/14         2/9  1/21\n",
       "Not Play   5/14         2/5    1/7         2/5  2/35"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = weather.rename(columns={\"prior\": str(\"prior\"+str(updates)), \"unnorm\": \"prior\", \"likelihood\":(\"likelihood\"+str(updates))})\n",
    "weather = weather.drop(columns={\"posterior\"})\n",
    "updates += 1\n",
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior1</th>\n",
       "      <th>likelihood1</th>\n",
       "      <th>prior2</th>\n",
       "      <th>likelihood2</th>\n",
       "      <th>prior3</th>\n",
       "      <th>likelihood3</th>\n",
       "      <th>prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Play</th>\n",
       "      <td>9/14</td>\n",
       "      <td>1/3</td>\n",
       "      <td>3/14</td>\n",
       "      <td>2/9</td>\n",
       "      <td>1/21</td>\n",
       "      <td>2/3</td>\n",
       "      <td>2/63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not Play</th>\n",
       "      <td>5/14</td>\n",
       "      <td>2/5</td>\n",
       "      <td>1/7</td>\n",
       "      <td>2/5</td>\n",
       "      <td>2/35</td>\n",
       "      <td>1/5</td>\n",
       "      <td>2/175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prior1 likelihood1 prior2 likelihood2 prior3 likelihood3  prior\n",
       "Play       9/14         1/3   3/14         2/9   1/21         2/3   2/63\n",
       "Not Play   5/14         2/5    1/7         2/5   2/35         1/5  2/175"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if_playHum2 = Fraction(len(dfPlay[dfPlay[\"Humidity\"] == \"Normal\"]) , len(dfPlay))\n",
    "if_notHum2 = Fraction(len(dfNoPlay[dfNoPlay[\"Humidity\"] == \"Normal\"]) , len(dfNoPlay))\n",
    "weather[\"likelihood\"] = if_playHum2, if_notHum2\n",
    "update(weather)\n",
    "#weather\n",
    "weather = weather.rename(columns={\"prior\": str(\"prior\"+str(updates)), \"unnorm\": \"prior\", \"likelihood\":(\"likelihood\"+str(updates))})\n",
    "weather = weather.drop(columns={\"posterior\"})\n",
    "updates += 1\n",
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last Update Step\n",
    "\n",
    "After this update I'll keep the posterior probability, since we are done, and I'll drop all the interim prior probabilities since we have no use for them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior1</th>\n",
       "      <th>likelihood1</th>\n",
       "      <th>likelihood2</th>\n",
       "      <th>likelihood3</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>unnorm</th>\n",
       "      <th>posterior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Play</th>\n",
       "      <td>9/14</td>\n",
       "      <td>1/3</td>\n",
       "      <td>2/9</td>\n",
       "      <td>2/3</td>\n",
       "      <td>2/3</td>\n",
       "      <td>4/189</td>\n",
       "      <td>125/152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not Play</th>\n",
       "      <td>5/14</td>\n",
       "      <td>2/5</td>\n",
       "      <td>2/5</td>\n",
       "      <td>1/5</td>\n",
       "      <td>2/5</td>\n",
       "      <td>4/875</td>\n",
       "      <td>27/152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prior1 likelihood1 likelihood2 likelihood3 likelihood unnorm  \\\n",
       "Play       9/14         1/3         2/9         2/3        2/3  4/189   \n",
       "Not Play   5/14         2/5         2/5         1/5        2/5  4/875   \n",
       "\n",
       "         posterior  \n",
       "Play       125/152  \n",
       "Not Play    27/152  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if_playWind2 = Fraction(len(dfPlay[dfPlay[\"Windy\"] == \"f\"]) , len(dfPlay))\n",
    "if_notWind2 = Fraction(len(dfNoPlay[dfNoPlay[\"Windy\"] == \"f\"]) , len(dfNoPlay))\n",
    "weather[\"likelihood\"] = if_playWind2, if_notWind2\n",
    "update(weather)\n",
    "weather.drop(columns={\"prior2\", \"prior\", \"prior3\"}, inplace=True)\n",
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/189\n"
     ]
    }
   ],
   "source": [
    "# Self Check\n",
    "# Play unnormalized probabilities\n",
    "print(Fraction(9,14)*Fraction(1,3)*Fraction(2,9)*Fraction(2,3)*Fraction(2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "What we are left with here is a series of likelihoods that each modify our prior probability. If we're keen, we also notice that this series of likelihoods translates directly to the top part of the Bayes equation. The bottom bit is always the same, and we only need that to normalize, so the result of the prediction is whichever unnorm probability is higher. Here 4/189 is more likely than 4/875, so we predict we'll play. \n",
    "\n",
    "This is all our classifier needs to do! We just take the prior probabilities and all the likelihoods, multiply them through, and pick the most likely outcome!! This should be pretty easy to put into place:\n",
    "<ul>\n",
    "<li> The training part of the model can just calculate all of these likelihoods and prior probabilities. Each one was just simple math, so we'll calculate all of them and store them in some kind of list (a dictionary, actually).\n",
    "    <ul>\n",
    "    <li> E.g. the likelihood of playing golf if it is sunny can be calculated and saved, same with the prob of not playing if it is windy, etc...\n",
    "    </ul>\n",
    "<li> The predicting part is just looking up the prior and the matching likelihoods from our dictionary of precalculated values, and doing the math. \n",
    "</ul>\n",
    "\n",
    "We are awesome!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Naive Bayes\n",
    "\n",
    "Below we have most of the Naive Bayes algorithm. The \"real\" ones from sklearn or other packages are basically the same as this - normally just with slightly better error handling, a few more options, and maybe some optimizations for speed - but the idea and execution is almost the same. One change that is actually different in ours is that we are using data in its dataframe format within our algorithm. This is a relatively minor change, and doesn't change any of the concepts behind what we are doing, what it does is make the code a little easier to read and understand as humans, as we can use things like the dataframe's \"columns\" variable. An implementation using arrays (to work exactly like the sklearn ones) would be almost the same, but places where we refer to columns by names would be replaced by indicies. \n",
    "\n",
    "We can use some print statements to look at exactly what is going on inside our model. This is also a good exercise as if we can't figure something out, printing the current state is the easiest way to diagnose it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class  NaiveBayes(object):\n",
    "\tdef __init__(self):\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\t\tAttributes:\n",
    "\t\t\t\tlikelihoods: Likelihood of each feature per class\n",
    "\t\t\t\tclass_priors: Prior probabilities of classes \n",
    "\t\t\t\tpred_priors: Prior probabilities of features \n",
    "\t\t\t\tfeatures: All features of dataset\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\tself.features = list\n",
    "\t\tself.likelihoods = {} # All of the possible feature-value pairs\n",
    "\t\tself.class_priors = {} # All class priors\n",
    "\t\tself.pred_priors = {} # All the predictor priors (for the bottom)\n",
    "\n",
    "\t\tself.X_train = np.array\n",
    "\t\tself.y_train = np.array\n",
    "\t\tself.train_size = int\n",
    "\t\tself.num_feats = int\n",
    "\n",
    "\tdef fit(self, X, y):\n",
    "\n",
    "\t\tself.features = list(X.columns)\n",
    "\t\tself.X_train = X\n",
    "\t\tself.y_train = y\n",
    "\t\tself.train_size = X.shape[0]\n",
    "\t\tself.num_feats = X.shape[1]\n",
    "\n",
    "\t\t# Generate a list of all the possible \"likelihoods\"\n",
    "\t\t# Each one is a feature_outcome pair, e.g. from the golf\n",
    "\t\t# one: Outlook_sunny, Temperature_hot, etc...\n",
    "\t\tfor feature in self.features:\n",
    "\t\t\t# Initialize the list of possible values for each feature in the big dictionary of features. \n",
    "\t\t\tself.likelihoods[feature] = {}\n",
    "\t\t\tself.pred_priors[feature] = {}\n",
    "\n",
    "\t\t\t# Loop through all of the values that this feature can take on, and add that\n",
    "\t\t\t# as a possibility to the list of likelihoods for that feature. \n",
    "\t\t\tfor feat_val in np.unique(self.X_train[feature]):\n",
    "\t\t\t\tself.pred_priors[feature].update({feat_val: 0})\n",
    "\t\t\t\t#print(feat_val)\n",
    "\t\t\t\tfor outcome in np.unique(self.y_train):\n",
    "\t\t\t\t\tself.likelihoods[feature].update({feat_val+'_'+outcome:0})\n",
    "\t\t\t\t\tself.class_priors.update({outcome: 0})\n",
    "\t\t\t\t\t#print('\\t'+feat_val+'_'+outcome)\n",
    "\t\t\n",
    "\t\t# These functions build the rest of the \"learned knowledge\"\n",
    "\t\t# of the model. \n",
    "\t\t# Calculate the priors \n",
    "\t\tself._calc_class_prior()\n",
    "\t\t# Calculate the probability of each likelihood\n",
    "\t\t# We precalculate and save each one so when predictions come\n",
    "\t\t# we can just look up the probabilities and multiply. \n",
    "\t\tself._calc_likelihoods()\n",
    "\t\t# Generate prior probs for each feature\n",
    "\t\tself._calc_predictor_prior()\n",
    "\n",
    "\tdef _calc_class_prior(self):\n",
    "\n",
    "\t\t\"\"\" P(c) - Prior Class Probability \"\"\"\n",
    "\n",
    "\t\tfor outcome in np.unique(self.y_train):\n",
    "\t\t\toutcome_count = sum(self.y_train == outcome)\n",
    "\t\t\tself.class_priors[outcome] = outcome_count / self.train_size\n",
    "\t\t\t#print(outcome, outcome_count, self.class_priors[outcome])\n",
    "\n",
    "\tdef _calc_likelihoods(self):\n",
    "\n",
    "\t\t\"\"\" P(x|c) - Likelihood \"\"\"\n",
    "\n",
    "\t\tfor feature in self.features:\n",
    "\t\t\t#print(\"\\n Likelihoods for:\", feature)\n",
    "\t\t\tfor outcome in np.unique(self.y_train):\n",
    "\t\t\t\toutcome_count = sum(self.y_train == outcome)\n",
    "\t\t\t\tfeat_likelihood = self.X_train[feature][self.y_train[self.y_train == outcome].index.values.tolist()].value_counts().to_dict()\n",
    "\t\t\t\t#print(\"Outcome:\", outcome)\n",
    "\n",
    "\t\t\t\tfor feat_val, count in feat_likelihood.items():\n",
    "\t\t\t\t\tself.likelihoods[feature][feat_val + '_' + outcome] = count/outcome_count\n",
    "\t\t\t\t\t#print(self.likelihoods[feature], self.likelihoods[feature][feat_val + '_' + outcome])\n",
    "\n",
    "\n",
    "\tdef _calc_predictor_prior(self):\n",
    "\n",
    "\t\t\"\"\" P(x) - Evidence \"\"\"\n",
    "\n",
    "\t\tfor feature in self.features:\n",
    "\t\t\tfeat_vals = self.X_train[feature].value_counts().to_dict()\n",
    "\t\t\t#print(feat_vals)\n",
    "\n",
    "\t\t\tfor feat_val, count in feat_vals.items():\n",
    "\t\t\t\tself.pred_priors[feature][feat_val] = count/self.train_size\n",
    "\t\t\t\t#print(self.pred_priors[feature][feat_val])\n",
    "\n",
    "\n",
    "\tdef predict(self, X):\n",
    "\n",
    "\t\t\"\"\" Calculates Posterior probability P(c|x) \"\"\"\n",
    "\t\t# Make predictions:\n",
    "\t\t# look up each likelihood, multiply out the likelihood\n",
    "\t\t# normalize and make a prediction of the highest. \n",
    "\t\tresults = []\n",
    "\t\tX = np.array(X)\n",
    "\t\tprint(\"\\n Predictions:\")\n",
    "\t\t# Loop through the things that we are predicting. \n",
    "\t\t# Each query is one record from X, our dataset of features. \n",
    "\t\tfor query in X:\n",
    "\t\t\tprobs_outcome = {}\n",
    "\t\t\tfor outcome in np.unique(self.y_train):\n",
    "\t\t\t\t# Get the prior probability of the outcome\n",
    "\t\t\t\tprior = self.class_priors[outcome]\n",
    "\t\t\t\tlikelihood = 1\n",
    "\t\t\t\tevidence = 1\n",
    "\n",
    "\t\t\t\t# Loop through each feature, and its value. \n",
    "\t\t\t\t# get the likelihood for that feature, \n",
    "\t\t\t\t# update the running probability with that likelihood. \n",
    "\t\t\t\tfor feat, feat_val in zip(self.features, query):\n",
    "\t\t\t\t\tlikelihood *= self.likelihoods[feat][feat_val + '_' + outcome]\n",
    "\t\t\t\t\tevidence *= self.pred_priors[feat][feat_val]\n",
    "\n",
    "\t\t\t\t# This is the Bayes final calculation\n",
    "\t\t\t\tposterior = (likelihood * prior) / (evidence)\n",
    "\t\t\t\t# store the postirior probability in the array of the results. \n",
    "\t\t\t\t# each row of data we are predicting gets a prediction, so we end up with a bunch. \n",
    "\t\t\t\tprobs_outcome[outcome] = posterior\n",
    "\n",
    "\t\t\t# Translate the posterior probs to a prediction i.e. what is the actual predicted class. \n",
    "\t\t\t# The prediction is whichever outcome is most likely. \n",
    "\t\t\tresult = max(probs_outcome, key = lambda x: probs_outcome[x])\n",
    "\t\t\tresults.append(result)\n",
    "\t\t# Return an array of all the predictions, just like we are used to getting from any model\n",
    "\t\treturn np.array(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(df):\n",
    "\n",
    "\t\"\"\" partioning data into features and target \"\"\"\n",
    "\n",
    "\tX = df.drop([df.columns[-1]], axis = 1)\n",
    "\ty = df[df.columns[-1]]\n",
    "\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weather Dataset:\n",
      "\n",
      " Predictions:\n",
      "Train Accuracy: 0.9285714285714286\n",
      "\n",
      " Predictions:\n",
      "Query 1:- [['Rainy' 'Mild' 'Normal' 't']] ---> ['yes']\n",
      "\n",
      " Predictions:\n",
      "Query 2:- [['Overcast' 'Cool' 'Normal' 't']] ---> ['yes']\n",
      "\n",
      " Predictions:\n",
      "Query 3:- [['Sunny' 'Hot' 'High' 't']] ---> ['no']\n"
     ]
    }
   ],
   "source": [
    "#Weather Dataset\n",
    "print(\"\\nWeather Dataset:\")\n",
    "\n",
    "\n",
    "#print(df)\n",
    "\n",
    "#Split fearures and target\n",
    "X,y  = pre_processing(df)\n",
    "\n",
    "nb_clf = NaiveBayes()\n",
    "nb_clf.fit(X, y)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(accuracy_score(y, nb_clf.predict(X))))\n",
    "\n",
    "#Query 1:\n",
    "query = np.array([['Rainy','Mild', 'Normal', 't']])\n",
    "print(\"Query 1:- {} ---> {}\".format(query, nb_clf.predict(query)))\n",
    "\n",
    "#Query 2:\n",
    "query = np.array([['Overcast','Cool', 'Normal', 't']])\n",
    "print(\"Query 2:- {} ---> {}\".format(query, nb_clf.predict(query)))\n",
    "\n",
    "#Query 3:\n",
    "query = np.array([['Sunny','Hot', 'High', 't']])\n",
    "print(\"Query 3:- {} ---> {}\".format(query, nb_clf.predict(query)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Notes\n",
    "\n",
    "We can see here, Bayes works totally differently from a logistic regression, even though it performs the same work. \n",
    "\n",
    "There are a few stipulations to using Naive Bayes, and a few varieties made to deal with scenarios that don't meet those stipulations:\n",
    "<ul>\n",
    "<li> Naive Bayes only works with categorical features. \n",
    "    <ul>\n",
    "    <li> Other versions of Bayes, such as Gaussian Bayes, allow numerical features to be used. For the Gaussian version, the probabilities are basically changed from the counting we did here, to probability estimates from a normal distribution. \n",
    "    </ul>\n",
    "<li> Normalization isn't relevant to Naive Bayes. \n",
    "<li> Encoding categorical varaibles isn't required. \n",
    "    <ul>\n",
    "    <li><b>Note:</b> this is generally true for the algorithm itself, but implementations of NB that you <b><i>might</i></b> use may require numerical inputs. That's a choice whoever made the library made in the design, NB handles categorical strings fine by default. \n",
    "    </ul>\n",
    "<li> Naive Bayes makes an assumption of independance between each feature, or that one feature's value does not impact another feature. This assumption is often not totally true in the real world (e.g. sunny and hot may tend to come together). The more independent the varaibles are from each other, the more reliable the results will be. \n",
    "<li> Naive Bayes can produce multinomial predictions (predicting between more than 2 classes) very easily. Our model above does it by default - each outcome has a probability of occuring, and the most likely one wins. \n",
    "    <ul>\n",
    "    <li> We will look into multiple class predictions more in the ML class, they are not always as simple as they are with Bayes. \n",
    "    <li> Each outcome is basically one row of a Bayes table, and we can handle 3+ with no real changes. \n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "### Bayes Uses and Benefits\n",
    "\n",
    "Bayes models are often used in things like spam detection. Naive Bayes can handle text inputs, and it is very fast to calculate, so that is an ideal scenario for the strength of the algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Model\n",
    "\n",
    "We are predicting the last column, the model. We have multiple classes for our output, and a bunch of categorical inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_cluster</th>\n",
       "      <th>make</th>\n",
       "      <th>segment</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>is_esc</th>\n",
       "      <th>is_adjustable_steering</th>\n",
       "      <th>is_tpms</th>\n",
       "      <th>is_parking_sensors</th>\n",
       "      <th>is_parking_camera</th>\n",
       "      <th>rear_brakes_type</th>\n",
       "      <th>...</th>\n",
       "      <th>is_rear_window_defogger</th>\n",
       "      <th>is_brake_assist</th>\n",
       "      <th>is_power_door_locks</th>\n",
       "      <th>is_central_locking</th>\n",
       "      <th>is_power_steering</th>\n",
       "      <th>is_driver_seat_height_adjustable</th>\n",
       "      <th>is_day_night_rear_view_mirror</th>\n",
       "      <th>is_ecw</th>\n",
       "      <th>is_speed_alert</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21211</th>\n",
       "      <td>C8</td>\n",
       "      <td>1</td>\n",
       "      <td>B1</td>\n",
       "      <td>CNG</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Drum</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>M8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38111</th>\n",
       "      <td>C12</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>CNG</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Drum</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5549</th>\n",
       "      <td>C5</td>\n",
       "      <td>1</td>\n",
       "      <td>B2</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Drum</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>M6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5199</th>\n",
       "      <td>C8</td>\n",
       "      <td>1</td>\n",
       "      <td>B1</td>\n",
       "      <td>CNG</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Drum</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>M8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26260</th>\n",
       "      <td>C15</td>\n",
       "      <td>3</td>\n",
       "      <td>C2</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Disc</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>M4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      area_cluster  make segment fuel_type is_esc is_adjustable_steering  \\\n",
       "21211           C8     1      B1       CNG     No                     No   \n",
       "38111          C12     1       A       CNG     No                     No   \n",
       "5549            C5     1      B2    Petrol     No                    Yes   \n",
       "5199            C8     1      B1       CNG     No                     No   \n",
       "26260          C15     3      C2    Diesel    Yes                    Yes   \n",
       "\n",
       "      is_tpms is_parking_sensors is_parking_camera rear_brakes_type  ...  \\\n",
       "21211      No                Yes                No             Drum  ...   \n",
       "38111      No                Yes                No             Drum  ...   \n",
       "5549       No                Yes                No             Drum  ...   \n",
       "5199       No                Yes                No             Drum  ...   \n",
       "26260     Yes                Yes               Yes             Disc  ...   \n",
       "\n",
       "      is_rear_window_defogger  is_brake_assist is_power_door_locks  \\\n",
       "21211                      No               No                 Yes   \n",
       "38111                      No               No                  No   \n",
       "5549                       No              Yes                 Yes   \n",
       "5199                       No               No                 Yes   \n",
       "26260                     Yes              Yes                 Yes   \n",
       "\n",
       "      is_central_locking is_power_steering is_driver_seat_height_adjustable  \\\n",
       "21211                Yes               Yes                               No   \n",
       "38111                 No               Yes                               No   \n",
       "5549                 Yes               Yes                              Yes   \n",
       "5199                 Yes               Yes                               No   \n",
       "26260                Yes               Yes                              Yes   \n",
       "\n",
       "      is_day_night_rear_view_mirror is_ecw is_speed_alert model  \n",
       "21211                            No    Yes            Yes    M8  \n",
       "38111                            No     No            Yes    M1  \n",
       "5549                            Yes    Yes            Yes    M6  \n",
       "5199                             No    Yes            Yes    M8  \n",
       "26260                            No    Yes            Yes    M4  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"data/bayes_multi.csv\")\n",
    "df2 = df2.sample(10000, random_state=42)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[[\"make\", \"gear_box\"]] = df2[[\"make\", \"gear_box\"]].astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M1     2536\n",
       "M4     2462\n",
       "M6     2317\n",
       "M8      743\n",
       "M7      458\n",
       "M3      442\n",
       "M9      364\n",
       "M5      257\n",
       "M10     179\n",
       "M2      177\n",
       "M11      65\n",
       "Name: model, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"model\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes for Execution:\n",
    "\n",
    "For this one we have a few things to watch out for when making predictions. The main thing is that we don't have anything in place to handle the zero probability problem. To avoid this, I tested it and set the random state arguments in the random bits - that should ensure that the randomness is always the same, so if it worked for me once, you should get the same splits. We also have a large dataset and a small test split, so the odds of getting one of those is pretty low. If you dropped the random state argument, it could happen, and you could get an error. The probability is low and it is random, so the odds are it will still work. At any point in time it might fail though. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Predictions:\n",
      "Test Accuracy: 0.996\n"
     ]
    }
   ],
   "source": [
    "x2, y2 = pre_processing(df2)\n",
    "\n",
    "columns = df2.columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x2, y2, test_size=0.1, stratify=y2, random_state=42)\n",
    "nb_2 = NaiveBayes()\n",
    "nb_2.fit(X_train, y_train)\n",
    "\n",
    "print(\"Test Accuracy: {}\".format(accuracy_score(y_test, nb_2.predict(X_test))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml3950')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d722d3adfa415172c1f5238b519fb86b488acdae450fd691ab06c09f4ca9173"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
